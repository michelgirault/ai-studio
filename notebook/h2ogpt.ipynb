{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook download and install stable diffusion webui for fine tuning and testing including the use of S3 as model and datasets repostory\n",
    "#declaration of variable to be use\n",
    "export HF_TOKEN=\n",
    "export HF_USERNAME=\n",
    "#details for git folders\n",
    "export HF_REPO_LLAVA=LLaVA-proto\n",
    "export HF_REPO_LLAMA=Llama-2-proto\n",
    "export HF_REPO_SD=sd-2-proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to the right folder\n",
    "cd apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone the main repository of h2o\n",
    "git clone https://github.com/h2oai/h2ogpt.git\n",
    "echo \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create local env\n",
    "python3 -m venv h2ogpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the git repository \n",
    "source h2ogpt/bin/activate\n",
    "cd h2ogpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install requiements lib\n",
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies and lib for h20gpt\n",
    "pip install -r requirements.txt\n",
    "pip install -r reqs_optional/requirements_optional_langchain.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pack of additional inforamtio\n",
    "pip uninstall llama_cpp_python llama_cpp_python_cuda -y\n",
    "pip install -r reqs_optional/requirements_optional_llamacpp_gpt4all.txt --no-cache-dir\n",
    "pip install -r reqs_optional/requirements_optional_langchain.urls.txt\n",
    "pip install -r reqs_optional/requirements_optional_langchain.urls.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with the model selected\n",
    "python3 generate.py --base_model=TheBloke/Mistral-7B-Instruct-v0.2-GGUF --prompt_type=mistral --max_seq_len=4096"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
